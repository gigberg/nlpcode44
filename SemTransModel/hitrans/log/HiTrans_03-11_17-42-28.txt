2024-03-11 17:42:28 - [line:164] - INFO: Namespace(alpha=0.95, batch_size=8, bert_lr=1e-05, d_ff=768, d_model=768, device=0, dropout=0.5, epochs=20, evaluate=False, heads=6, hidden_dim=768, input_max_length=512, layers=1, lr=5e-05, max_grad_norm=1.0, seed=123, weight_decay=1e-05)
2024-03-11 17:42:28 - [line:174] - INFO: Loading data...
2024-03-11 18:57:50 - [line:206] - INFO: Epoch: 0 Train Loss: 1.1535 F1: 0.3276
2024-03-11 18:57:51 - [line:208] - INFO: Epoch: 0 Dev Loss: 1.1248 F1: 0.2832
2024-03-11 18:57:51 - [line:211] - INFO: ---------------------------------
2024-03-11 18:58:09 - [line:206] - INFO: Epoch: 1 Train Loss: 1.0687 F1: 0.3802
2024-03-11 18:58:09 - [line:208] - INFO: Epoch: 1 Dev Loss: 1.0345 F1: 0.4389
2024-03-11 18:58:09 - [line:211] - INFO: ---------------------------------
2024-03-11 18:58:23 - [line:206] - INFO: Epoch: 2 Train Loss: 0.9456 F1: 0.5381
2024-03-11 18:58:23 - [line:208] - INFO: Epoch: 2 Dev Loss: 0.9315 F1: 0.5378
2024-03-11 18:58:23 - [line:211] - INFO: ---------------------------------
2024-03-11 18:58:38 - [line:206] - INFO: Epoch: 3 Train Loss: 0.8588 F1: 0.6087
2024-03-11 18:58:38 - [line:208] - INFO: Epoch: 3 Dev Loss: 0.9146 F1: 0.5526
2024-03-11 18:58:38 - [line:211] - INFO: ---------------------------------
2024-03-11 18:58:52 - [line:206] - INFO: Epoch: 4 Train Loss: 0.8135 F1: 0.6484
2024-03-11 18:58:52 - [line:208] - INFO: Epoch: 4 Dev Loss: 0.9004 F1: 0.5634
2024-03-11 18:58:52 - [line:211] - INFO: ---------------------------------
2024-03-11 18:59:07 - [line:206] - INFO: Epoch: 5 Train Loss: 0.7592 F1: 0.6854
2024-03-11 18:59:07 - [line:208] - INFO: Epoch: 5 Dev Loss: 0.9168 F1: 0.5715
2024-03-11 18:59:07 - [line:211] - INFO: ---------------------------------
2024-03-11 18:59:21 - [line:206] - INFO: Epoch: 6 Train Loss: 0.7221 F1: 0.7198
2024-03-11 18:59:21 - [line:208] - INFO: Epoch: 6 Dev Loss: 0.9212 F1: 0.5732
2024-03-11 18:59:21 - [line:211] - INFO: ---------------------------------
